---
title: 'Preprocessing_LJ_orthologues'
author: 'Maud Van Ginneken'
output:
  pdf_document:
    number_sections: yes
    keep_tex: yes
  html_document:
    df_print: paged
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, autodep = TRUE, warning = FALSE, 
                      message = FALSE, echo = FALSE, eval = TRUE, tidy = TRUE,
                      fig.width = 6, fig.height = 3.5, purl = TRUE, 
                      fig.show = "hold", fig.pos = "p")
```

```{r}
#library("reticulate")
#library("SingleCellExperiment")
library("Seurat")
library("SeuratDisk")
library("tidyverse")
#library("destiny")
#library("rgl")
#library("car")
#library("gridExtra")
#library("pheatmap")
library("tibble")
#library("reshape2")
library("dplyr")
```

\tableofcontents

# Introduction

We will use the Seurat 'ecosystem' in R for our preprocessing workflow:

We create a Seurat object from a count matrix (a big matrix storing all RNA transcript counts for every cell). The object serves as a container that contains both data (like the count matrix) and analysis results (like PCA or clustering results) for a single-cell dataset. See: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html

Ref: similar workflow (on the same dataset) in Python using Scanpy: https://training.galaxyproject.org/training-material/topics/single-cell/tutorials/scrna-plant/tutorial.html

# Data

```{r}
set.seed(1679)
```

# Load OrthoFinder orthologues and orthogroups 

```{r}
# Orthologues from OrthoFinder results 
AT_LJ <- read.table(file = '/scratch/gent/472/vsc47291/MA1_CompPlantDev/data/Proteomes/primary_transcripts/OrthoFinder/Results_Mar05/Orthologues/Orthologues_Arabidopsis_thaliana/Arabidopsis_thaliana__v__Lotus_japonicus.tsv', sep = '\t', header = TRUE)

# Extract one-on-one orthologues 
AT_LJ_Orthologues <- subset(AT_LJ, !grepl(",", Arabidopsis_thaliana) & !grepl(",", Lotus_japonicus), select = -Orthogroup)
```

```{r}
#Load dataset
LJ_root <- readRDS("/scratch/gent/472/vsc47291/MA1_CompPlantDev/data/Frank2023/frank2023_counts.rds") 

obj.list <- SplitObject(LJ_root, split.by = "Condition")

# Create vector in which LJ gene names are replaced by AT orthologues 
ljcounts <- obj.list[["Control"]]@assays[["RNA"]]@counts@Dimnames[[1]]

ortho_names <- replace(ljcounts, which(ljcounts %in% AT_LJ_Orthologues$Lotus_japonicus), AT_LJ_Orthologues$Arabidopsis_thaliana[AT_LJ_Orthologues$Lotus_japonicus %in% ljcounts])

# Replace Seurat gene name vectors by new vector containing AT orthologous gene names
obj.list[["Control"]]@assays[["RNA"]]@counts@Dimnames[[1]] = ortho_names
obj.list[["Control"]]@assays[["RNA"]]@data@Dimnames[[1]] = ortho_names
rownames(obj.list[["Control"]]@assays[["RNA"]]@meta.features) = ortho_names

LJ_root <- CreateSeuratObject(counts = obj.list[["Control"]]@assays[["RNA"]], project = "LJ_root")
```

# Dimension reduction

```{r}
# Histogram before normalization 
hist(colSums(LJ_root@assays$RNA),
     breaks = 100,
     main = "Library size before normalisation",
     xlab = "Library size")
```

```{r fig.width=8}
# Select 5000 most variable features 
LJ_root <- FindVariableFeatures(LJ_root, selection.method = "vst", nfeatures = 5000)

# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(LJ_root), 10)

# Plot variable features with and without labels
plot1 <- VariableFeaturePlot(LJ_root)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
plot1 + plot2
```

```{r}
# Scaling the data 
all_genes <- rownames(LJ_root)
LJ_root <- ScaleData(LJ_root, features = all_genes)
```

```{r fig.height = 6}
# Linear dimensional reduction
LJ_root <- RunPCA(LJ_root, npcs = 100, features = VariableFeatures(object = LJ_root))

# Examine and visualize PCA results a few different ways
print(LJ_root[["pca"]], dims = 1:5, nfeatures = 5)

# Visualize loadings
VizDimLoadings(LJ_root, dims = 1:2, reduction = "pca")
```

## Annotate ploidy

```{r}
#extract matrix of expression values
processed_counts <- as.matrix(LJ_root@assays$RNA$scale.data)
```

```{r}
# Merge the reference expression profile with the normalized expression matrix of our sample  
merge.rownames <- function (x,y){
  dat <- merge(x = x, y = y, by = "row.names")
  rownames(dat) <- dat$Row.names
  dat <- dat[,-1]
  return(dat)
}

load(file="../data/Shahan2022/endo_exp.RD")
ploidy <- Reduce(merge.rownames, list(endo_exp,processed_counts))
```

```{r}
# Prepare customized label name (optional)
ploidy_label=c("2C", "4C", "8C", "16C")
ploidy[,1:10]
```

```{r}
# Calculating the correlation coefficient of each cell to each reference expression profile and annotate the cell as the label that it has the highest correlation coefficient with.  
ploidy_stat <- suppressWarnings(sapply(5:ncol(ploidy),
                                       function(i)
                                         sapply(1:4,
                                                function(j)
                                                  cor.test(ploidy[, i], ploidy[, j], method = "pearson")[c(3, 4)])))

ploidy_cor <- ploidy_stat[seq(2, nrow(ploidy_stat), 2), ]
ploidy_pvalue <- ploidy_stat[seq(1, nrow(ploidy_stat) - 1, 2), ]

ploidy_max <-
  sapply(1:(ncol(ploidy) - 4), function(i)
    max(as.numeric(ploidy_cor[, i])))

ploidy_ident <-
  sapply(1:(ncol(ploidy) - 4), function(i)
    ploidy_label[which(as.numeric(ploidy_cor[, i]) == max(as.numeric(ploidy_cor[, i])))])

ploidy_maxp <-
  sapply(1:(ncol(ploidy) - 4), function(i)
    as.numeric(ploidy_pvalue[, i])[which(as.numeric(ploidy_cor[, i]) == max(as.numeric(ploidy_cor[, i])))])

names(ploidy_max) <- ploidy_ident
```

```{r}
# Store the annotation, correlation coefficient and the p-value in Seurat object
LJ_root@meta.data$ploidy.ID.P <- as.character(ploidy_ident)
LJ_root@meta.data$ploidy.cor.P <- ploidy_max
LJ_root@meta.data$ploidy.pvalue.p <- ploidy_maxp

# In case there is a cell with insufficient info for annotation, label them as unknown
LJ_root@meta.data$ploidy.ID.P[which(LJ_root@meta.data$ploidy.ID.P=="character(0)")]="unknown"
```

```{r}
LJ_root <- RunUMAP(LJ_root, dims = 1:60, reduction.name = "umap60")
DimPlot(LJ_root, reduction = "umap60")
```

```{r fig.height = 16 fig.width = 16}

#options(repr.plot.width=16, repr.plot.height=16)
order <- c("2C","4C","8C","16C","unknown")
palette <- c("#DCEDC8","#42B3D5","#FDEA6F","#CF4F29","#cccccc")

LJ_root$ploidy.ID.P <- factor(LJ_root$ploidy.ID.P, levels=order[sort(match(unique(LJ_root$ploidy.ID.P), order))])
color <- palette

ploidyplot <- DimPlot(LJ_root, group.by="ploidy.ID.P", cols=color, reduction = 'umap60', dims = c(1,2)) + labs(x = "", y = "", title = "Ploidy levels")

pdf(file = "LJ_ploidyplot2.pdf", width = 16, height = 16)
ploidyplot
dev.off()
```

```{r}
FeaturePlot(LJ_root, reduction = "umap60", features = 'AT2G03830')
```

```{r}
SaveH5Seurat(LJ_root)
LJ_root <- LoadH5Seurat('/scratch/gent/472/vsc47291/MA1_CompPlantDev/preprocessing/LJ_root.h5Seurat')
getwd()
```